{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenting blood vessels in optical images of the retina using U-Net.\n",
    "\n",
    "**Model is based on:**  \n",
    "Ronneberger et al., \"[U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597),\" MICCAI, 2015\n",
    "\n",
    "**Dataset is from:**  \n",
    "Hoover et al., \"[Locating Blood Vessels in Retinal Images by Piece-wise Threhsold Probing of a Matched Filter Response](http://cecas.clemson.edu/~ahoover/stare/),\" IEEE Transactions on Medical Imaging, 19(3) 203-10, 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSTARE(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, database, subset, nimages, transform=None):\n",
    "        \"\"\"Constructor.\n",
    "\n",
    "        database: path to the .npz file.\n",
    "        subset: can be 'train', 'val', or 'test'.\n",
    "        nimages: number of random cropped regions to extract from original images.\n",
    "        transform: transforms used for data augmentation.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        fimages = sorted((database / 'images').glob('*.ppm'))\n",
    "        fmasks = sorted((database / 'masks1').glob('*.ppm'))\n",
    "        if subset == 'train':\n",
    "            indices = list(set(range(20)) - set((6, 7, 11, 12)))\n",
    "        elif subset == 'val':\n",
    "            indices = [6, 11]\n",
    "        elif subset == 'test':\n",
    "            indices = [7, 12]\n",
    "        self._images = np.array([imageio.imread(x) for i, x in enumerate(fimages) if i in indices])\n",
    "        self._masks = np.array([imageio.imread(x) for i, x in enumerate(fmasks) if i in indices])\n",
    "        self._transform = transform\n",
    "        self._nimages = nimages\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Dataset size.\"\"\"\n",
    "        return self._nimages\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Image and its corresponding mask at a given index.\"\"\"\n",
    "        image = self._images[index % len(self._images)]\n",
    "        mask = self._masks[index % len(self._masks)]\n",
    "        image = image.transpose([2,0,1])  # transpose dimensions such that image shape is: channels, height, width\n",
    "        image = image.astype(np.float32) / 255  # convert image from 8-bit integer to 32-bit floating precision\n",
    "        mask = mask.astype(np.float32) / 255\n",
    "        image = torch.as_tensor(image.copy())  # cast NumPy array to Torch tensor\n",
    "        mask = torch.as_tensor(mask.copy()).unsqueeze(0)\n",
    "        if self._transform is not None:\n",
    "            while True:\n",
    "                combined = torch.cat([image, mask], dim=0)\n",
    "                combined = self._transform(combined)\n",
    "                image2 = combined[:len(image)]\n",
    "                mask2 = combined[len(image):]\n",
    "                if (100 * mask2.sum() / mask2.numel()) < 5:  # skip if mask occupies <5% of the image\n",
    "                    continue\n",
    "                image = image2\n",
    "                mask = mask2\n",
    "                break\n",
    "        return image, mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_DICOM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
